{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train script\n",
    "# adapted from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import ssl\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.models import VisionTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.utils.data import random_split\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUp:\n",
    "    def __init__(self, num_classes, alpha=0.2, method=1):\n",
    "        self.alpha = alpha\n",
    "        self.method = method\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, images, labels):\n",
    "        labels = one_hot(labels, self.num_classes)\n",
    "        \n",
    "        if self.method == 1:\n",
    "            lambd = torch.distributions.Beta(self.alpha, self.alpha).sample((images.size(0),)).to(images.device)\n",
    "        elif self.method == 2:\n",
    "            lambd = torch.distributions.Uniform(0.1, 0.4).sample((images.size(0),)).to(images.device)\n",
    "\n",
    "        #mixing random images\n",
    "        indices = torch.randperm(images.size(0))\n",
    "\n",
    "        images1, labels1 = images, labels\n",
    "        images2, labels2 = images[indices], labels[indices]\n",
    "\n",
    "        mix_images = lambd.view(-1, 1, 1, 1) * images1 + (1 - lambd).view(-1, 1, 1, 1) * images2\n",
    "        mix_labels = lambd.view(-1, 1) * labels1 + (1 - lambd).view(-1, 1) * labels2\n",
    "\n",
    "        return mix_images, mix_labels\n",
    "    \n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    \n",
    "def calculate_metrics(preds, labels, classes):\n",
    "    # Initialize the confusion matrix\n",
    "    confusion_matrix = torch.zeros(len(classes), len(classes))\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "    recall = confusion_matrix.diag() / confusion_matrix.sum(0)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Calculate true positives\n",
    "    true_positives = confusion_matrix.diag()\n",
    "\n",
    "    return precision, recall, f1_score, true_positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scaler = GradScaler()\n",
    "## cifar-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 36\n",
    "\n",
    "#dataset\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# full_dataset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "\n",
    "#do subset \n",
    "from torch.utils.data import Subset\n",
    "# Define the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Get the number of samples in the train and test sets\n",
    "num_train_samples = len(trainset)\n",
    "num_test_samples = len(testset)\n",
    "\n",
    "# Calculate the indices for the quarter of the datasets\n",
    "train_indices = torch.randperm(num_train_samples)[:num_train_samples//6]\n",
    "test_indices = torch.randperm(num_test_samples)[:num_test_samples//6]\n",
    "\n",
    "# Create subsets\n",
    "trainset_subset = Subset(trainset, train_indices)\n",
    "testset_subset = Subset(testset, test_indices)\n",
    "\n",
    "# Concatenate the subsets\n",
    "full_dataset_subset = torch.utils.data.ConcatDataset([trainset_subset, testset_subset])\n",
    "\n",
    "#split\n",
    "#80/20 dev to test\n",
    "dev_size = int(0.8 * len(full_dataset_subset))\n",
    "test_size = len(full_dataset_subset) - dev_size\n",
    "development_set, holdout_test_set  = torch.utils.data.random_split(full_dataset_subset, [dev_size, test_size])\n",
    "#90/10 train/ test of dev set\n",
    "dev_train_size = int(0.9 * len(development_set))\n",
    "dev_test_size = len(development_set) - dev_train_size\n",
    "development_train_set, development_test_set  = torch.utils.data.random_split(development_set, [dev_test_size, dev_train_size])\n",
    "print(len(full_dataset_subset))\n",
    "print(len(development_set))\n",
    "print(len(development_train_set))\n",
    "print(len(development_test_set))\n",
    "print(len(holdout_test_set))\n",
    "\n",
    "#dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(development_train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(development_test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "holdoutloader = torch.utils.data.DataLoader(holdout_test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def train_and_evaluate(trainloader, validationloader, holdoutloader, num_epochs, classes, save_filename, sampling_method):\n",
    "    t0 = time.time()\n",
    "    ## vision transformer \n",
    "    net = VisionTransformer(image_size=32, patch_size=8, num_layers=6, num_heads=8,\n",
    "                            hidden_dim=384, mlp_dim=1536, dropout=0.0, num_classes=len(classes)).to(device)\n",
    "\n",
    "    ## loss and optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    mixUp = MixUp(num_classes=len(classes), alpha=2, method=sampling_method)\n",
    "    results_train = []\n",
    "    losses = []\n",
    "    ## train\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        running_loss = 0.0\n",
    "        print('Epoch {}, sampling method {}'.format(epoch+1, sampling_method))\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            images, labels = data\n",
    "            images, labels = mixUp(images, labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            with autocast():\n",
    "                all_labels_train = []\n",
    "                all_predictions_train = []\n",
    "                outputs = net(images.to(device))\n",
    "                #compute accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                # Convert one-hot encoded labels to class indices\n",
    "                labels_indices = labels.argmax(dim=1).to(device)\n",
    "                #calculate extra metrics\n",
    "                all_labels_train.extend(labels_indices.tolist())\n",
    "                all_predictions_train.extend(predicted.tolist())\n",
    "                precision, recall, f1_score, true_positives = calculate_metrics(torch.tensor(all_labels_train), torch.tensor(all_predictions_train), classes)\n",
    "                #calculate accuracy\n",
    "                correct_train += (predicted == labels_indices).sum().item()\n",
    "                #calculate loss\n",
    "                loss = criterion(outputs, labels_indices)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)  # Call scaler.step() instead of optimizer.step()\n",
    "            scaler.update()  # Update the scaler\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        average_loss = running_loss / i\n",
    "        losses.append(running_loss / i) \n",
    "        print('Average loss: %.3f' % average_loss)      \n",
    "        print('Training done.')\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        print('Epoch {}, Training accuracy: {}%'.format(epoch+1, train_accuracy))\n",
    "        #accuracy results\n",
    "        results_train.append(train_accuracy) \n",
    "        for i, class_name in enumerate(classes):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            print(f\"Precision: {precision[i]}\")\n",
    "            print(f\"Recall: {recall[i]}\")\n",
    "            print(f\"F1-score: {f1_score[i]}\")\n",
    "            print(f\"True positives: {true_positives[i]}\")\n",
    "            print()\n",
    "              \n",
    "        # evaluation on validation\n",
    "        net.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        results_validation = []\n",
    "        print(\"Evaluating validation set\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_labels_val = []\n",
    "            all_predictions_val = []\n",
    "            for data in validationloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels.to(device)).sum().item()\n",
    "                #collect labels and predictions\n",
    "                all_labels_val.extend(labels.to(device).tolist())\n",
    "                all_predictions_val.extend(predicted.tolist())\n",
    "\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        print('Epoch {}, Validation accuracy: {}%'.format(epoch+1, val_accuracy))\n",
    "        results_validation.append(val_accuracy)    # accuracy on validation set\n",
    "        precision, recall, f1_score, true_positives = calculate_metrics(torch.tensor(all_labels_val), torch.tensor(all_predictions_val), classes)\n",
    "        for i, class_name in enumerate(classes):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            print(f\"Precision: {precision[i]}\")\n",
    "            print(f\"Recall: {recall[i]}\")\n",
    "            print(f\"F1-score: {f1_score[i]}\")\n",
    "            print(f\"True positives: {true_positives[i]}\")\n",
    "            print()\n",
    "            \n",
    "        #evaluation on test\n",
    "        results_test = []\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        print(\"Evaluating holdout set\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            all_labels_test = []\n",
    "            all_predictions_test = []\n",
    "            for data in holdoutloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels.to(device)).sum().item()\n",
    "                #collect labels and predictions\n",
    "                all_labels_test.extend(labels.to(device).tolist())\n",
    "                all_predictions_test.extend(predicted.tolist())\n",
    "\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        print('Epoch {}, Testing accuracy: {}%'.format(epoch+1, val_accuracy))\n",
    "        results_test.append(test_accuracy)    # accuracy on validation set\n",
    "        precision, recall, f1_score, true_positives = calculate_metrics(torch.tensor(all_labels_test), torch.tensor(all_predictions_test), classes)\n",
    "        for i, class_name in enumerate(classes):\n",
    "            print(f\"Class: {class_name}\")\n",
    "            print(f\"Precision: {precision[i]}\")\n",
    "            print(f\"Recall: {recall[i]}\")\n",
    "            print(f\"F1-score: {f1_score[i]}\")\n",
    "            print(f\"True positives: {true_positives[i]}\")\n",
    "            print()\n",
    "    \n",
    "    # After training, plot the accuracies\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), results_train, label='Train')\n",
    "    plt.plot(range(1, num_epochs+1), results_validation, label='Test')\n",
    "    plt.plot(range(1, num_epochs+1), results_test, label='Train')\n",
    "    plt.title('Accuracy vs. Epoch sampling method '+ str(sampling_method) )\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('Accuracy_vs_Epoch_metod_'+ str(sampling_method)+ '.png')\n",
    "    plt.show()\n",
    "    \n",
    "    torch.save(net.state_dict(), save_filename)\n",
    "    print(f\"Model {sampling_method} saved.\")\n",
    "    \n",
    "#do smapling method 1\n",
    "train_and_evaluate(trainloader, validationloader, holdoutloader, 1, classes, 'saved_model_sampling_method1_task3.pt', 1)\n",
    "\n",
    "#do sampling method 2\n",
    "train_and_evaluate(trainloader, validationloader, holdoutloader,  1, classes, 'saved_model_sampling_method2_task3.pt', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
