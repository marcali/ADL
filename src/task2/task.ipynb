{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train script\n",
    "# adapted from: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import ssl\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision.models import VisionTransformer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUp:\n",
    "    def __init__(self, num_classes, alpha=0.2, method=1):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.method = method\n",
    "        self.num_classes = num_classes\n",
    "        if(self.method == 1):\n",
    "            self.lambd = torch.distributions.Beta(self.alpha, self.alpha).sample()\n",
    "        if(self.method == 2):\n",
    "            self.lambd = torch.distributions.Uniform(0.1, 0.4).sample()\n",
    "\n",
    "    def __call__(self, images, labels):\n",
    "        labels = one_hot(labels, self.num_classes)\n",
    "\n",
    "        # images\n",
    "        images1 = torch.cat([images, images[0].unsqueeze(0)])\n",
    "        images2 = torch.cat([images[1:], images[0].unsqueeze(0)])\n",
    "        \n",
    "        # labels\n",
    "        labels1 = torch.cat([labels, labels[0].unsqueeze(0)])\n",
    "        labels2 = torch.cat([labels[1:], labels[0].unsqueeze(0)])\n",
    "        \n",
    "        # Perform mixup\n",
    "        mix_images = self.lambd * images1 + (1 - self.lambd) * images2\n",
    "        mix_labels = self.lambd * labels1 + (1 - self.lambd) * labels2\n",
    "\n",
    "        return mix_images, mix_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "scaler = GradScaler()\n",
    "## cifar-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#training set\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#test set\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# example images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter) # note: for pytorch versions (<1.14) use dataiter.next()\n",
    "\n",
    "#TODO:\n",
    "#mix up\n",
    "mixup = MixUp(len(classes))\n",
    "images, labels = mixup(images, labels)\n",
    "\n",
    "#save images\n",
    "im = Image.fromarray((torch.cat(images.split(1,0),3).squeeze()/2*255+.5*255).permute(1,2,0).numpy().astype('uint8'))\n",
    "im.save(\"mixup.jpg\")\n",
    "print('mixup.jpg saved.')\n",
    "print('Ground truth labels:' + ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "\n",
    "def train_and_evaluate(trainloader, testloader, num_epochs, save_filename, sampling_method):\n",
    "    ## vision transformer \n",
    "    net = VisionTransformer(image_size=32, patch_size=2, num_layers=6, num_heads=16,\n",
    "                            hidden_dim=512, mlp_dim=2048, num_classes=len(classes)).cuda()\n",
    "\n",
    "    ## loss and optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "\n",
    "    ## train\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        running_loss = 0.0\n",
    "        mixUp = MixUp(num_classes=len(classes),alpha=0.2,method=sampling_method)\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            images, labels = data\n",
    "            images, labels = mixUp(images, labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            with autocast():\n",
    "                outputs = net(images.cuda())\n",
    "                #compute accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels.cuda()).sum().item()\n",
    "                loss = criterion(outputs, labels.cuda())\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)  # Call scaler.step() instead of optimizer.step()\n",
    "            scaler.update()  # Update the scaler\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:    # print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        print('Training done.')\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        print('Epoch {}, Training accuracy: {}%'.format(epoch+1, train_accuracy))\n",
    "        results_train.append(train_accuracy)        \n",
    "        # evaluation on test\n",
    "        net.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.cuda())\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        print('Epoch {}, Testing accuracy: {}%'.format(epoch+1, test_accuracy))\n",
    "        results_test.append(test_accuracy)    # save trained model\n",
    "    \n",
    "    # After training, plot the accuracies\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), results_train, label='Train')\n",
    "    plt.plot(range(1, num_epochs+1), results_test, label='Test')\n",
    "    plt.title('Accuracy vs. Epoch sampling method ', sampling_method )\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Get some random test images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Get predictions for these images\n",
    "    outputs = net(images.cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # For each image in the batch\n",
    "    for i in range(36):\n",
    "        ax = fig.add_subplot(6, 6, i+1, xticks=[], yticks=[])\n",
    "        imshow(images[i])\n",
    "        ax.set_title(f\"GT:{classes[labels[i]]}\\nPred:{classes[predicted[i]]}\", color=(\"green\" if predicted[i]==labels[i] else \"red\"))\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f\"result_{sampling_method}.png\")\n",
    "    print('result.png saved.')\n",
    "    \n",
    "    torch.save(net.state_dict(), save_filename)\n",
    "    print('Model saved.')\n",
    "    \n",
    "#do smapling method 1\n",
    "train_and_evaluate(trainloader, testloader, 20, 'saved_model_sampling_method1.pt', 1)\n",
    "\n",
    "#do sampling method 2\n",
    "train_and_evaluate(trainloader, testloader, 20, 'saved_model_sampling_method1.pt', 2)\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-cw1-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
